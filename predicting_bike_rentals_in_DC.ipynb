{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Introduction **\n",
    "\n",
    "This project looks at communal bike rentals in the Washington D.C. area. The dataset includes information around the time of rental and the weather. Our goal of this project is to test different modles to see if we can predict the total number of bikes rented in a given hour (the 'cnt' column - which is a combination of the casual and registered columns). We will use Linear Regression, a Decision Tree and Random Forest to make our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_rentals = pd.read_csv('bike_rental_hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "5        6  2011-01-01       1   0     1   5        0        6           0   \n",
      "6        7  2011-01-01       1   0     1   6        0        6           0   \n",
      "7        8  2011-01-01       1   0     1   7        0        6           0   \n",
      "8        9  2011-01-01       1   0     1   8        0        6           0   \n",
      "9       10  2011-01-01       1   0     1   9        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81     0.0000       3          13   16  \n",
      "1           1  0.22  0.2727  0.80     0.0000       8          32   40  \n",
      "2           1  0.22  0.2727  0.80     0.0000       5          27   32  \n",
      "3           1  0.24  0.2879  0.75     0.0000       3          10   13  \n",
      "4           1  0.24  0.2879  0.75     0.0000       0           1    1  \n",
      "5           2  0.24  0.2576  0.75     0.0896       0           1    1  \n",
      "6           1  0.22  0.2727  0.80     0.0000       2           0    2  \n",
      "7           1  0.20  0.2576  0.86     0.0000       1           2    3  \n",
      "8           1  0.24  0.2879  0.75     0.0000       1           7    8  \n",
      "9           1  0.32  0.3485  0.76     0.0000       8           6   14  \n"
     ]
    }
   ],
   "source": [
    "# Exploring the initial data\n",
    "\n",
    "print(bike_rentals.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6972., 3705., 2659., 1660.,  987.,  663.,  369.,  188.,  139.,\n",
       "          37.]),\n",
       " array([  1. ,  98.6, 196.2, 293.8, 391.4, 489. , 586.6, 684.2, 781.8,\n",
       "        879.4, 977. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwCAw/8HkCb6D0gnLtwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fb4e4fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gain insight on the 'cnt' column:\n",
    "\n",
    "plt.hist(bike_rentals['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekday       0.026900\n",
      "workingday    0.030284\n",
      "holiday       0.030927\n",
      "windspeed     0.093234\n",
      "mnth          0.120638\n",
      "weathersit    0.142426\n",
      "season        0.178056\n",
      "yr            0.250495\n",
      "instant       0.278379\n",
      "hum           0.322911\n",
      "hr            0.394071\n",
      "atemp         0.400929\n",
      "temp          0.404772\n",
      "casual        0.694564\n",
      "registered    0.972151\n",
      "cnt           1.000000\n",
      "Name: cnt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Explore the correlations with the 'cnt' column:\n",
    "\n",
    "cor_map = bike_rentals.corr()\n",
    "print(abs(cor_map['cnt']).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the hour variable to a time of day variable\n",
    "\n",
    "def assign_label(hour):\n",
    "    if 6 > hour <= 12:\n",
    "        tod = 1\n",
    "    elif 12 > hour <= 18:\n",
    "        tod = 2\n",
    "    elif 18 > hour <= 24:\n",
    "        tod = 3\n",
    "    else:\n",
    "        tod = 4\n",
    "    return tod\n",
    "\n",
    "bike_rentals['time_label'] = bike_rentals['hr'].apply(assign_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekday       0.026900\n",
      "workingday    0.030284\n",
      "holiday       0.030927\n",
      "windspeed     0.093234\n",
      "mnth          0.120638\n",
      "weathersit    0.142426\n",
      "season        0.178056\n",
      "yr            0.250495\n",
      "instant       0.278379\n",
      "hum           0.322911\n",
      "hr            0.394071\n",
      "atemp         0.400929\n",
      "temp          0.404772\n",
      "time_label    0.422126\n",
      "casual        0.694564\n",
      "registered    0.972151\n",
      "cnt           1.000000\n",
      "Name: cnt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Re-look at the correlations with the time_label column.\n",
    "\n",
    "cor_map = bike_rentals.corr()\n",
    "print(abs(cor_map['cnt']).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ERROR METRIC **\n",
    "\n",
    "We will use the RMSE metric to measure our data.\n",
    "\n",
    "We will start with linear regression on the data for our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we need to randomize and split up the data into train \n",
    "# and test groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_rentals = bike_rentals.sample(frac=1).reset_index(drop=True)\n",
    "split_num = math.floor(bike_rentals.shape[0] * .8)\n",
    "train = bike_rentals.iloc[:split_num]\n",
    "test = bike_rentals.iloc[split_num:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we need to create a list of columns to use for our regression\n",
    "# We will remove 'cnt', 'casual' and 'registered' because they would\n",
    "# inform the algorithm of the answer. We will remove 'atemp'\n",
    "# because it is a function of temp and we don't want to duplicate.\n",
    "# We will also remove dteday. \n",
    "\n",
    "features = list(bike_rentals.drop(['cnt',\n",
    "                               'casual',\n",
    "                               'registered',\n",
    "                               'atemp',\n",
    "                               'dteday'], axis=1\n",
    "                            ).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train[features],train['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  140.02498009201648\n"
     ]
    }
   ],
   "source": [
    "predictions = lr.predict(test[features])\n",
    "lr_rmse = mean_squared_error(test['cnt'],predictions)**(1/2)\n",
    "print('Test RMSE: ',lr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Analysis of RMSE**\n",
    "\n",
    "This RMSE seems high. This could be from the distribution of the data. Most of the rentals are low but some are extremely high and those may be getting penalized by the Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  57.53472209249011\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(train[features],train['cnt'])\n",
    "\n",
    "predictions = dtr.predict(test[features])\n",
    "dt_rmse = mean_squared_error(test['cnt'], predictions)**(1/2)\n",
    "print('Test RMSE: ', dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is extremely high pointing to severe overfitting. Let's try to tweak it a bit and find out what the best parameters and values would be to change. We'll start with min_samples and then test depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE 1 min_sample_leaf:  56.17407546983465\n",
      "Test RMSE 2 min_sample_leaf:  51.4998384667567\n",
      "Test RMSE 3 min_sample_leaf:  50.64805261000953\n",
      "Test RMSE 4 min_sample_leaf:  49.872696810633535\n",
      "Test RMSE 5 min_sample_leaf:  49.85990412383016\n",
      "Test RMSE 6 min_sample_leaf:  49.82276486340461\n",
      "Test RMSE 7 min_sample_leaf:  50.12602319544563\n",
      "Test RMSE 8 min_sample_leaf:  50.40822005051152\n",
      "Test RMSE 9 min_sample_leaf:  50.742867000998324\n",
      "Test RMSE 10 min_sample_leaf:  50.61971051881094\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    dtr = DecisionTreeRegressor(min_samples_leaf=i)\n",
    "    dtr.fit(train[features],train['cnt'])\n",
    "    \n",
    "    predictions = dtr.predict(test[features])\n",
    "    dt_rmse = mean_squared_error(test['cnt'], predictions)**(1/2)\n",
    "    print('Test RMSE',i,'min_sample_leaf: ', dt_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE 10 max_depth:  57.45390957522606\n",
      "Test RMSE 11 max_depth:  53.95801508057443\n",
      "Test RMSE 12 max_depth:  52.13574324508572\n",
      "Test RMSE 13 max_depth:  50.80867112040207\n",
      "Test RMSE 14 max_depth:  50.02784173635927\n",
      "Test RMSE 15 max_depth:  49.90533003873262\n",
      "Test RMSE 16 max_depth:  50.0097848010563\n",
      "Test RMSE 17 max_depth:  49.66862451668388\n",
      "Test RMSE 18 max_depth:  49.92936790176642\n",
      "Test RMSE 19 max_depth:  49.769556560181535\n",
      "Test RMSE 20 max_depth:  49.97218173073685\n",
      "Test RMSE 21 max_depth:  49.883801457126\n",
      "Test RMSE 22 max_depth:  49.86479235577875\n",
      "Test RMSE 23 max_depth:  49.84970232353811\n",
      "Test RMSE 24 max_depth:  49.78910449438584\n",
      "Test RMSE 25 max_depth:  49.98963683597963\n",
      "Test RMSE 26 max_depth:  49.80465960339818\n",
      "Test RMSE 27 max_depth:  49.73871530208742\n",
      "Test RMSE 28 max_depth:  49.8322844267886\n",
      "Test RMSE 29 max_depth:  49.82284549014391\n",
      "Test RMSE 30 max_depth:  49.78609949820087\n",
      "Test RMSE 31 max_depth:  49.76965304633447\n",
      "Test RMSE 32 max_depth:  49.98865587944474\n",
      "Test RMSE 33 max_depth:  49.84629134647089\n",
      "Test RMSE 34 max_depth:  49.7533311384581\n",
      "Test RMSE 35 max_depth:  49.97181120134966\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,36):\n",
    "    dtr = DecisionTreeRegressor(max_depth=i, min_samples_leaf=5)\n",
    "    dtr.fit(train[features],train['cnt'])\n",
    "    \n",
    "    predictions = dtr.predict(test[features])\n",
    "    dt_rmse = mean_squared_error(test['cnt'], predictions)**(1/2)\n",
    "    print('Test RMSE',i,'max_depth: ', dt_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE max_depth = 24, min_samples_leaf = 5:  49.694285123745686\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth = 24,min_samples_leaf = 5)\n",
    "dtr.fit(train[features],train['cnt'])\n",
    "    \n",
    "predictions = dtr.predict(test[features])\n",
    "dt_rmse = mean_squared_error(test['cnt'], predictions)**(1/2)\n",
    "print('Test RMSE max_depth = 24, min_samples_leaf = 5: ', dt_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quick Analysis **\n",
    "\n",
    "After playing around with it a little, it looks like the optimal spot may be somewhere around 5 min sample leafs and 24 max depth. If we wanted to be even more sure we could run multiple iterations of this and take the average. With this data and these features we could get our RMSE down more easily with min_samples_leaf than max_depth. It is probably worth dropping max_depth to speed up the operation, especially if we were working with a larger data set.\n",
    "\n",
    "Compared to Linear Regression, the Decision Tree Regressor produced a significantly better RMSE value. \n",
    "\n",
    "Next we try applying a Random Forest Regressor. We'll start with the default setting and then experiment with the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  44.22067839352342\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(train[features],train['cnt'])\n",
    "\n",
    "predictions = rfr.predict(test[features])\n",
    "rfr_rmse = mean_squared_error(test['cnt'],predictions)**(1/2)\n",
    "print('Test RMSE: ',rfr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that the random forest regressor is fitting better to the data than either the linear regression model or the decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE with min_sample_leaf = 1 : 42.40520315144481\n",
      "Test RMSE with min_sample_leaf = 2 : 43.93583347223653\n",
      "Test RMSE with min_sample_leaf = 3 : 43.42160125236751\n",
      "Test RMSE with min_sample_leaf = 4 : 42.665645362975795\n",
      "Test RMSE with min_sample_leaf = 5 : 43.23000203531048\n",
      "Test RMSE with min_sample_leaf = 6 : 44.55830945001479\n",
      "Test RMSE with min_sample_leaf = 7 : 44.29162679848522\n",
      "Test RMSE with min_sample_leaf = 8 : 45.469474356145575\n",
      "Test RMSE with min_sample_leaf = 9 : 45.46561971367632\n",
      "Test RMSE with min_sample_leaf = 10 : 46.494637370078784\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    rfr = RandomForestRegressor(min_samples_leaf = i)\n",
    "    rfr.fit(train[features],train['cnt'])\n",
    "    \n",
    "    predictions = rfr.predict(test[features])\n",
    "    rfr_rmse = mean_squared_error(test['cnt'],predictions)**(1/2)\n",
    "    \n",
    "    print('Test RMSE with min_sample_leaf =',i,':',rfr_rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE with max_depth = 5 : 106.42065053847816\n",
      "Test RMSE with max_depth = 6 : 96.94846406862241\n",
      "Test RMSE with max_depth = 7 : 77.55125786100407\n",
      "Test RMSE with max_depth = 8 : 63.51726870473583\n",
      "Test RMSE with max_depth = 9 : 55.077035918129404\n",
      "Test RMSE with max_depth = 10 : 51.267290578189716\n",
      "Test RMSE with max_depth = 11 : 48.241792003909055\n",
      "Test RMSE with max_depth = 12 : 45.096648081816184\n",
      "Test RMSE with max_depth = 13 : 44.53405419880526\n",
      "Test RMSE with max_depth = 14 : 44.25946627815348\n",
      "Test RMSE with max_depth = 15 : 43.221324691509956\n",
      "Test RMSE with max_depth = 16 : 43.236465528132726\n",
      "Test RMSE with max_depth = 17 : 42.881675514838285\n",
      "Test RMSE with max_depth = 18 : 43.03986080162767\n",
      "Test RMSE with max_depth = 19 : 41.745910248954935\n",
      "Test RMSE with max_depth = 20 : 42.85420246624095\n",
      "Test RMSE with max_depth = 21 : 43.7905443005039\n",
      "Test RMSE with max_depth = 22 : 43.40525234706869\n",
      "Test RMSE with max_depth = 23 : 42.7564075274159\n",
      "Test RMSE with max_depth = 24 : 42.331911811568446\n",
      "Test RMSE with max_depth = 25 : 42.87467131594572\n",
      "Test RMSE with max_depth = 26 : 42.66881453086236\n",
      "Test RMSE with max_depth = 27 : 43.559489917519734\n",
      "Test RMSE with max_depth = 28 : 41.68985161658093\n",
      "Test RMSE with max_depth = 29 : 43.63753084114925\n",
      "Test RMSE with max_depth = 30 : 42.461395716875195\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,31):\n",
    "    rfr = RandomForestRegressor(max_depth = i)\n",
    "    rfr.fit(train[features],train['cnt'])\n",
    "    \n",
    "    predictions = rfr.predict(test[features])\n",
    "    rfr_rmse = mean_squared_error(test['cnt'],predictions)**(1/2)\n",
    "    \n",
    "    print('Test RMSE with max_depth =',i,':',rfr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE with n_estimators = 1 : 61.0588931686674\n",
      "Test RMSE with n_estimators = 2 : 54.60655512904096\n",
      "Test RMSE with n_estimators = 3 : 49.26225324405073\n",
      "Test RMSE with n_estimators = 4 : 46.939648553225716\n",
      "Test RMSE with n_estimators = 5 : 45.21351850349686\n",
      "Test RMSE with n_estimators = 6 : 43.0819661955827\n",
      "Test RMSE with n_estimators = 7 : 43.52227961032728\n",
      "Test RMSE with n_estimators = 8 : 43.715068456487074\n",
      "Test RMSE with n_estimators = 9 : 43.24218359164547\n",
      "Test RMSE with n_estimators = 10 : 43.84081119370374\n",
      "Test RMSE with n_estimators = 11 : 42.673241161492825\n",
      "Test RMSE with n_estimators = 12 : 42.630798598335275\n",
      "Test RMSE with n_estimators = 13 : 42.355544932030625\n",
      "Test RMSE with n_estimators = 14 : 42.04462166986254\n",
      "Test RMSE with n_estimators = 15 : 42.2571004301053\n",
      "Test RMSE with n_estimators = 16 : 42.7342376483036\n",
      "Test RMSE with n_estimators = 17 : 40.51342106788624\n",
      "Test RMSE with n_estimators = 18 : 41.36823888095526\n",
      "Test RMSE with n_estimators = 19 : 41.99649524098717\n",
      "Test RMSE with n_estimators = 20 : 41.908080925227814\n",
      "Test RMSE with n_estimators = 21 : 41.48455143823724\n",
      "Test RMSE with n_estimators = 22 : 41.48357272301846\n",
      "Test RMSE with n_estimators = 23 : 41.45488399439149\n",
      "Test RMSE with n_estimators = 24 : 41.742428819658116\n",
      "Test RMSE with n_estimators = 25 : 40.72640382724277\n",
      "Test RMSE with n_estimators = 26 : 41.39964113003055\n",
      "Test RMSE with n_estimators = 27 : 41.334364895836885\n",
      "Test RMSE with n_estimators = 28 : 41.324449325443524\n",
      "Test RMSE with n_estimators = 29 : 40.8637269557986\n",
      "Test RMSE with n_estimators = 30 : 41.13436567529654\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):\n",
    "    rfr = RandomForestRegressor(n_estimators=i)\n",
    "    rfr.fit(train[features],train['cnt'])\n",
    "    \n",
    "    predictions = rfr.predict(test[features])\n",
    "    rfr_rmse = mean_squared_error(test['cnt'],predictions)**(1/2)\n",
    "    \n",
    "    print('Test RMSE with n_estimators =',i,':',rfr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some idea of the optimal spots for our parameters lets try a combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  38.533008881148696\n",
      "Test RMSE:  41.21640049461768\n",
      "Test RMSE:  41.328605556472986\n",
      "Test RMSE:  43.03447820090611\n",
      "Test RMSE:  42.647576587352106\n",
      "Test RMSE:  42.37705339734473\n",
      "Test RMSE:  39.48390867311073\n",
      "Test RMSE:  41.626729099425695\n",
      "Test RMSE:  40.86559493900309\n",
      "Test RMSE:  40.90189174329043\n",
      "\n",
      "Avg RMSE for Random Forest: 41.20152475726722\n"
     ]
    }
   ],
   "source": [
    "rmse_list = []\n",
    "\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "X = bike_rentals.index\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    train = bike_rentals.iloc[train_index]\n",
    "    test = bike_rentals.iloc[test_index]\n",
    "    \n",
    "    rfr = RandomForestRegressor(max_depth = 19, n_estimators = 29)\n",
    "    rfr.fit(train[features],train['cnt'])\n",
    "    \n",
    "    predictions = rfr.predict(test[features])\n",
    "    rfr_rmse = mean_squared_error(test['cnt'],predictions)**(1/2)\n",
    "    \n",
    "    rmse_list.append(rfr_rmse)\n",
    "    \n",
    "    print('Test RMSE: ',rfr_rmse)\n",
    "    \n",
    "avg_rmse = np.mean(rmse_list)\n",
    "print('')\n",
    "print('Avg RMSE for Random Forest:', avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion **\n",
    "\n",
    "We were able to get our RMSE down from 140.0 inially with linear regression to 41.2 with our random forest model. This was a great example of how different models work and how to test them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
